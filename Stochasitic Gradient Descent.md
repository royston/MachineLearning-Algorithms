##Stochasitic Gradient Descent
For Linear example, computing the derivative term can be expensive if the number of training exmaples is huge(because for every "step", sum has to be calculated over all training examples)

